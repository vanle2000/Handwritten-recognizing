{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b4cee6a",
   "metadata": {},
   "source": [
    "# Recognizing Handwritten Digits with the k-Nearest Neighbour Classification Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1524c711",
   "metadata": {},
   "source": [
    "## 1. Introduction:\n",
    "\n",
    "In this notebook, I will delve into the world of k-NN classification algorithm - one of the most popular and effective supervised learning techniques. Despite its simplicity, k-NN has proven to be a powerful tool for classification tasks in a variety of domains, ranging from image recognition to natural language processing.\n",
    "\n",
    "### 1.1. Purpose of Conducting\n",
    "However, implementing k-NN classifier is not a straightforward process and often poses several challenges. The most common concerns are determining the optimal value of k, selecting the appropriate distance metric, handling imbalanced datasets, and dealing with high-dimensional data. To address these challenges, I will conduct hyperparameter tuning on two key parameters: k neighbors and distance metrics. By optimizing these parameters, we may achieve better classification performance and improve the accuracy of our k-NN classifier. Moreover, we also implemented a weighted k-NN algorithm for MNIST database.\n",
    "### 1.2. Experiment Design\n",
    "One of the main challenges in k-NN is choosing the optimal number of neighbors (k) and distance metric. That's why I will conduct two experiments to find the optimal value of k and the best distance metrics for our classifier.\n",
    "* Experiment 1: Optimal k neighbors value In this experiment, I will vary the value of k and measure the accuracy of our model for each k value to determine the optimal k neighbors value.\n",
    "* Experiment 2: Distance Metrics In this experiment, we I explore three different distance metrics to calculate the distance between data points: Manhattan, Minkowski, and Cosine. I will compare the accuracy of our model for each distance metric to determine the best distance metric for our classifier.\n",
    "* Experiment 3: Implement a weighted k-NN algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "356401e7",
   "metadata": {},
   "source": [
    "## 2. Data Processing:\n",
    "\n",
    "### 2.1. MNIST Database\n",
    "The MNIST database is a database of 60,000 images of handwritten digits from 0 through 9 with numerical labels. This is commonly used for training various image processing systems and testing in the field of machine learning. To the right is a sample of labeled images included in the database [5].\n",
    "![MnistExamples.png](attachment:MnistExamples.png)\n",
    "**Image source: [5]**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39e97709",
   "metadata": {},
   "source": [
    "### 2.2. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "910082d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "from sklearn.metrics import confusion_matrix\n",
    "import gzip\n",
    "from numpy import linalg as LA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7b87136",
   "metadata": {},
   "source": [
    "### 2.3. Downloading MNIST Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "96699dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_url = \"http://yann.lecun.com/exdb/mnist/\"\n",
    "img_file = \"train-images-idx3-ubyte.gz\"\n",
    "labels_file = \"train-labels-idx1-ubyte.gz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a2ca7cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_MNIST():\n",
    "    \"\"\"\n",
    "    This is the function for downloading MNIST files where 'images' returns images of digits and \n",
    "    'label' gives the corresponding labels of images. \n",
    "    \n",
    "    \"\"\"\n",
    "    for fname in [img_file, labels_file]:\n",
    "        if Path(fname).is_file() :\n",
    "            print(f\"Found: {fname}\")\n",
    "            continue\n",
    "        r = requests.get(mnist_url + fname)\n",
    "        with open(fname, 'wb') as foo:\n",
    "            foo.write(r.content)\n",
    "            \n",
    "    with gzip.open(img_file, 'rb') as foo:\n",
    "         f = foo.read()\n",
    "    with gzip.open(labels_file, 'rb') as foo:\n",
    "         g = foo.read()\n",
    "    images = np.array([b for b in f[16:]]).reshape(-1, 28*28)\n",
    "    labels = np.array([b for b in g[8:]])\n",
    "    \n",
    "    return images,labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "689f5b5b",
   "metadata": {},
   "source": [
    "The images are grayscale and have a resolution of 28 x 28 pixels, resulting in a total of 784 pixels per image. Each pixel is represented by a value between 0 and 255, with higher values indicating darker shades. The dataset also includes labels for each image, indicating the true digit that the image represents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c50d7607",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found: train-images-idx3-ubyte.gz\n",
      "Found: train-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "images,labels = get_MNIST()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "df348297",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images shape:  (60000, 784)\n",
      "Lables shape:  (60000,)\n"
     ]
    }
   ],
   "source": [
    "print(\"Images shape: \", np.shape(images))\n",
    "print(\"Lables shape: \", np.shape(labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dee67d50",
   "metadata": {},
   "source": [
    "The `image` dataset has 60000 rows and 784 columns where each row represents a image of a single digit and labels is a \n",
    "1-diemnsional Numpy array which has 60000 entries each of them corresponds to the label of the digits in the images array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e798b19f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAoAAAAJpCAYAAAA9hoNpAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAABRy0lEQVR4nO3dd5RUVfb//b0BEVABCWIEVARFFMyoqAxiwiyj4oAIOsafio4gBlRGRZExggEjKjpGFEYMyIiYGB0jIyqIARBMIDkLnOePap9v73Orq7q6qrpu1Xm/1uq1+FTfuvcUp2/37tu7zlXnnAAAACAcNQo9AAAAAFQvCkAAAIDAUAACAAAEhgIQAAAgMBSAAAAAgaEABAAACEwQBaCqTlbVv1b3c1F4zH24mPuwMf/hYu4rp6gKQFWdpapdCz2OiqhqH1Vdr6rLy310LvS4SkHc515ERFUvVdWfVXWJqj6iqhsXekyloBjm/g+qOklVnarWKvRYSkXc519V26nqBFVdoKosrJtDRTD3G6vqHar6o6ouUtV7VXWjQo+rsoqqACwS/3HObVruY3KhB4T8U9UjROQKETlURFqKyA4i8vdCjgnVS1V7igiFX3h+F5FnReSsQg8E1e4KEdlbRNqJSGsR2VNEBhV0RBkoiQJQVTdX1fGqOr+sCh+vqtt6m+2oqv8tuzozTlUblXt+R1WdoqqLVXUqV+2KR4zm/gwRedg594VzbpGI3CAifaq4L1RCjOZeVLWBiFwnIpdXdR/ITFzm3zk3wzn3sIh8UfVXg0zEZe5F5FgRGe6cW+icmy8iw0XkzCruq9qVRAEoidcxSkRaiEhzEVklInd72/SWxMRsLSLrJDFRoqrbiMjLInKjiDQSkf4iMkZVm/oHUdXmZV8wzVOMZY+yPwV8rarX8KegvIvL3O8qIlPL5aki0kxVG1fxdSG9uMy9iMhNInKfiPyczQtCRuI0/6hecZl7Lfson7ct+4Uw9kqiAHTO/eacG+OcW+mcWyYiQ0TkEG+z0c65ac65FSJyjYicoqo1RaSXiLzinHvFObfBOTdRRD4SkW5JjjPHOdfQOTengqG8LYlLwVuISHcROU1EBuTkRSKpGM39piKypFz+49+bZfHykEJc5l5V9xaRA0VkRA5fHtKIy/yj+sVo7l8VkX6q2lRVtxSRi8ser5eDl5l3JVEAqmo9Vb1fVWer6lJJFGINyyb7Dz+U+/dsEdlIRJpI4jeIk8uq/MWqulhEOonIVpmOwzn3nXPu+7Ivqs9F5HoR+XMVXxYqIS5zLyLLRaR+ufzHv5dVYV+ohDjMvarWEJF7RaSfc25dFi8HGYrD/KMwYjT3Q0TkUxH5TESmiMhYSfSE/lqFfVW7kigAReQyEWkjIvs55+qLyMFlj5e/NLtduX83l8QkLZDEF8nosir/j49NnHNDczAu540BuReXuf9CRNqXy+1F5Bfn3G9V2BcqJw5zX18STeDPqOrPIvJh2eNzVfWgDPeFzMRh/lEYsZh759wq59yFzrltnHM7iMhvIvKxc259VV5UdSvGAnAjVa1T7qOWJP7MtkpEFpc1el6X5Hm9VLWtqtaTxJW558sm6QkROVZVj1DVmmX77JykoTQtVT1KVZuV/XtnSVx2HlfF14mo2M69iDwuImeVHWdzSbwT7NGqvEgkFde5XyKJHqMOZR9//BlpLxH5INMXiQrFdf5FE+qISO2yXEdZAiqX4jz326jq1mVfAx0l8TM/2VhiqRgLwFckMfF/fAwWkTtFpK4kqvv3ReS1JM8bLYkfyD+LSB0p+1u9c+4HETleRK4SkfmS+O1ggCT5v9FEQ+hyrbgh9FAR+Z+qrigb5wuSaA5HbsR27p1zr4nIMBF5UxJ/bpgtRfSNoAjEcu5dws9/fJTtSyRx9XdtFV8romI5/2ValI3pj3cBrxKRGZm9PKQQ57nfURJ/+l0hIo+JyBXOudczf4mFoc6xbiUAAEBIivEKIAAAALJAAQgAABAYCkAAAIDAUAACAAAEhgIQAAAgMCnvU6uqvEW4xDjnKr0wNfNfeio7/8x96eHcDxvnfrgqmnuuAAIAAASGAhAAACAwFIAAAACBoQAEAAAIDAUgAABAYCgAAQAAAkMBCAAAEBgKQAAAgMBQAAIAAASGAhAAACAwFIAAAACBoQAEAAAIDAUgAABAYCgAAQAAAkMBCAAAEJhahR4AEEd77bWXyRdeeKHJvXv3Nvnxxx83ecSIEZF9fvLJJzkaHQAA2eEKIAAAQGAoAAEAAAJDAQgAABAYdc5V/EnVij9ZRGrWrGlygwYNMt6H3wNWr149k9u0aWPy//t//y+yj1tvvdXk0047zeTVq1ebPHToUJP//ve/V26wKTjntLLblsr8p9OhQ4fIY5MmTTK5fv36Ge1zyZIlkccaN26c0T7yobLzH8rcV5dDDz3U5CeffNLkQw45xOQZM2bkfAyc+/kxaNAgk5N9n65Rw15r6dy5s8lvvfVWzsfl49wPV0VzzxVAAACAwFAAAgAABIYCEAAAIDCxXwewefPmkcdq165t8gEHHGByp06dTG7YsKHJ3bt3z83gypk7d67Jw4cPj2xz4oknmrxs2TKTp06danJ19IWEaN999zV5zJgxkW38PlG/V9afu7Vr15qcrN+vY8eOJvvrAvr7KHYHH3ywyf7/yYsvvlidwymoffbZx+QPP/ywQCNBtvr06WPywIEDTd6wYUPafaTqvQeqC1cAAQAAAkMBCAAAEBgKQAAAgMDErgfQX5PNX49NpGrr+OWa3+fhrwW1fPnyyHP8tb9++uknkxctWmRyPtYCC4G/RuOee+5p8hNPPGHyVlttlfExZs6cafKwYcNMfvrppyPPee+990z2v2ZuvvnmjMcRZ/5aZzvttJPJpdoD6K/5JiKy/fbbm9yiRQuTVSu9RB8KzJ+7OnXqFGgkSGW//fYzuVevXib7a2+KiOy6664p99m/f3+Tf/zxR5P99x+IRH/efPDBBymPUZ24AggAABAYCkAAAIDAUAACAAAEJnY9gHPmzDH5t99+i2yT6x7AZH+TX7x4scl/+tOfTPbXbBs9enROx4Squ//++03277mcC35f4aabbmpysjUc/Z643XffPefjipPevXub/J///KdAI6leyXpKzz77bJP9vqDp06fndUyouq5du5p80UUXpdw+2Vwec8wxJv/yyy/ZDwzGqaeeavJdd91lcpMmTUxO1nc7efJkk5s2bWryP/7xj5RjSLZPfx89evRIuY/qxBVAAACAwFAAAgAABIYCEAAAIDAUgAAAAIGJ3ZtAFi5caPKAAQMi2/gNtZ9++qnJw4cPT3mMzz77zOTDDjssss2KFStM9heI7NevX8pjoPrstddeJh999NEmp1tkN9kbNl566SWTb731VpP9BUD9r0F/UW8RkS5dumQ0rmKXbEHkEDz00ENpt/EXEkd8+Iv5jho1yuR0b0JM9kaB2bNnZz+wwNWqZcuVvffe2+QHH3zQZP+GAG+//bbJN9xwQ+QY7777rskbb7yxyc8++6zJhx9+eIoRJ3z00UdptymUML9DAwAABIwCEAAAIDAUgAAAAIGJXQ+gb+zYsZHHJk2aZPKyZctMbt++vclnnXWWyX4/l9/vl8wXX3xh8jnnnJP2OciPDh06mDxx4kST69evb7JzzuRXX33V5GQLRfs3Ch80aJDJfp/X/PnzTZ46dWpknxs2bDDZ71X0F5f+5JNPIvuIM39h62bNmhVoJIVVmYXq/a9ZxMcZZ5xh8tZbb51ye3/x4McffzzXQ4KI9OrVy+R0vbb+OeYvFL106dK0x/Sfk67nb+7cuZHHHnvssbTHKRSuAAIAAASGAhAAACAwFIAAAACBiX0PYDLp/na/ZMmSlJ/3b8z+zDPPRLbx+7VQGK1bt4485q8N6fdcLViwwOSffvrJZL8nY/ny5ZFjvPzyyylzLtStW9fkyy67zOSePXvm/Jj51K1bN5P911eq/F7H7bffPu1z5s2bl6/hIANNmjSJPHbmmWea7P8sWLx4sck33nhjzscVumRr9F111VUm+73d9957r8l+33Zlev58V199dUbbX3zxxZHH/P7wOOEKIAAAQGAoAAEAAAJDAQgAABCYouwBTGfw4MEm+/eK9dd469q1a2Qfr7/+es7HhfT8ey/6azaKRHvN/HUge/fubbJ/L8a49qY1b9680EPISps2bVJ+3l9Ls1T4X6PJ1j/8+uuvTfa/ZlE9WrZsafKYMWMy3seIESNMfvPNN7MZEkTk2muvNdnv9xMRWbt2rckTJkwweeDAgSavWrUq5THr1KkTecxf58//nuzfv93v/xw3blzKY8YNVwABAAACQwEIAAAQGApAAACAwJRkD6B/b19/3T//HqsPPvhgZB9+X4ffR3bPPfeY7K9JhKrZY489TPb7/ZI5/vjjTX7rrbdyOibkxocffljoIVSKfy/pI4880mT/nqTp7g8qEl3XzF9LDtXDn0v//tXJvPHGGybfddddOR1TiBo2bGjyBRdcYHKyn6d+z98JJ5yQ0TFbtWpl8pNPPhnZxn+/gO/55583ediwYRmNIW64AggAABAYCkAAAIDAUAACAAAEpiR7AH3ffvutyX369DF51KhRkeecfvrpKfMmm2xi8uOPP26yf/9ZVM7tt99usr/ukki0x69Yev5q1LC/b4V2v+lGjRplvY/27dub7H99+Gt6brvttibXrl3b5GT3W/bnyV9P7IMPPjB5zZo1JteqFf22+vHHH0ceQ/75fWJDhw5N+5x3333X5DPOOMPkdPeaR3r+eZjsnsw+/z67W2yxhcl9+/Y1+bjjjjO5Xbt2Jm+66aaRY/i9h35+4oknTPbfb1BsuAIIAAAQGApAAACAwFAAAgAABIYCEAAAIDBBvAnE9+KLL5o8c+bMyDb+mxEOPfRQk2+66SaTW7RoYfKQIUMi+5w3b15G4wzBMcccY3KHDh1MTrYg6L/+9a98Dilv/Dd9+K/ts88+q8bR5J7/Zgn/9Y0cOdLkZDd8T8dfuNd/E8i6detMXrlypclffvmlyY888kjkGP6i7/6bjH755ReT586da3LdunUj+5w+fXrkMeRey5YtTR4zZkzG+/juu+9M9ucb2Vu7dq3J8+fPN7lp06aR53z//fcmZ3rzhR9//NHkpUuXRrbZaqutTF6wYIHJL730UkbHjDuuAAIAAASGAhAAACAwFIAAAACBCbIH0Ddt2rTIY6eccorJxx57rMn+4tHnnnuuyTvttFNkn4cddlhVh1iy/H4pf4HQX3/9NfKcZ555Jq9jqoqNN97Y5MGDB6d9zqRJk0y+8sorczmkauff0H327NkmH3DAAVkfY86cOSaPHTvW5K+++srk999/P+tj+s455xyT/X4lv4cM1WfgwIEmV2Wx9cosFo3sLF682GR/we7x48dHnuMvJO/f4GHcuHEmP/rooyYvXLjQ5KeffjpyDL8HMNk2pYQrgAAAAIGhAAQAAAgMBSAAAEBg6AGsgN+jMHr0aJMfeughk/0bwB988MGRfXbu3NnkyZMnV3l8oVizZk3ksZ9++qkAI7H8nr9BgwaZPGDAgMhz/PXibrvtNpOXL1+eo9HFwy233FLoIeSFvyaoryprz6Fq/HVDDz/88Iye7/eNiYjMmDEjmyGhCj744AOTk60DmC3/Z/IhhxwS2cbvGS31fl6uAAIAAASGAhAAACAwFIAAAACBoQdQovcXFRH585//bPI+++xjst/z5/PvOSoi8vbbb1dhdGGLy31//V4jv8fv1FNPNTlZb1H37t1zPi7Ej3+vceTP66+/bvLmm2+ecnt/Xcg+ffrkekiIKX/N2WRrRPr3F2YdQAAAAJQUCkAAAIDAUAACAAAEJogewDZt2ph84YUXmnzSSSdFnrPllltmdIz169ebnGytuqrcl7LUqWrK7N8jUkSkX79++RySiIhceumlJl9zzTUmN2jQwOQnn3zS5N69e+dnYAD+f40bNzY53ffYe++91+RSW3sTFZswYUKhhxA7XAEEAAAIDAUgAABAYCgAAQAAAkMBCAAAEJiSeBOI/4aN0047zWT/TR8tW7bM+pgfffSRyUOGDDE5LgsYx52/8Kafk70ZZ/jw4SY/8sgjJv/2228md+zY0eTTTz/d5Pbt20eOse2225o8Z84ck/2GYr+5HOHw37jUunXryDb+AsSomlGjRplco0Zm1zCmTJmSy+GgiBxxxBGFHkLscAUQAAAgMBSAAAAAgaEABAAACEzsewCbNWsWeaxt27Ym33333SbvvPPOWR/3gw8+MPkf//iHyePGjTOZRZ7zo2bNmpHHLrjgApO7d+9u8tKlS03eaaedMj6u3yv05ptvmnzttddmvE+UJr9vNdO+NCTXoUOHyGNdu3Y12f++u3btWpPvuecek3/55ZfcDA5FZ4cddij0EGKH71QAAACBoQAEAAAIDAUgAABAYAreA9ioUSOT77//fpOT9YFk+7d8v7/rtttui2zjr/O2atWqrI6J5P7zn/+Y/OGHH5q8zz77pN2Hv1Zgsr7R8vx1Ap9++unINv369Ut7XCCZ/fffP/LYo48+Wv0DKXINGzaMPJZsXdDy5s2bZ3L//v1zOSQUsXfeecfkZL26ofXycwUQAAAgMBSAAAAAgaEABAAACEzeewD3228/kwcMGGDyvvvua/I222yT9TFXrlxpsn/v2JtuusnkFStWZH1MVM3cuXNNPumkk0w+99xzI88ZNGhQRse46667TL7vvvtM/uabbzLaH1Cefy9gAPEzbdo0k2fOnBnZxn9/wY477mjy/Pnzcz+wAuIKIAAAQGAoAAEAAAJDAQgAABCYvPcAnnjiiSlzOl9++WXksfHjx5u8bt06k/11/RYvXpzRMVE4P/30k8mDBw+ObJPsMaC6vPrqqyaffPLJBRpJaZs+fXrkMX8N106dOlXXcFBi/PcCiIg89NBDJg8ZMsTkiy66yORk9Ukx4QogAABAYCgAAQAAAkMBCAAAEBh1zlX8SdWKP4mi5Jyr9KJlzH/pqez8M/elh3M/bJz7Vv369SOPPfvssyZ37drV5BdeeMHkvn37mhzXNYUrmnuuAAIAAASGAhAAACAwFIAAAACBoQAEAAAIDG8CCQyN4GGjETxcnPth49xPz39jiL8Q9Pnnn2/y7rvvbnJcF4bmTSAAAAAQEQpAAACA4FAAAgAABIYewMDQBxQ2+oDCxbkfNs79cNEDCAAAABGhAAQAAAgOBSAAAEBgUvYAAgAAoPRwBRAAACAwFIAAAACBoQAEAAAIDAUgAABAYCgAAQAAAkMBCAAAEBgKQAAAgMBQAAIAAASGAhAAACAwFIAAAACBoQAEAAAIDAUgAABAYCgAAQAAAkMBCAAAEBgKQAAAgMBQAAIAAASGAhAAACAwFIAAAACBoQAEAAAIDAUgAABAYCgAAQAAAkMBCAAAEBgKQAAAgMBQAAIAAAQmiAJQVSer6l+r+7koPOY+XMx92Jj/cDH3lVNUBaCqzlLVroUeR0VU9QxV/VhVl6rqXFUdpqq1Cj2uUlAEc99OVSeo6gJVdYUeTykpgrnvoaozVHWJqv6qqo+pav1Cj6tUFMH8c+7nSdznvjxVnaSqrph+5hdVAVgE6onIJSLSRET2E5FDRaR/IQeEavO7iDwrImcVeiCodu+JyIHOuQYisoOI1BKRGws7JFQjzv3AqWpPSZz3RaUkCkBV3VxVx6vqfFVdVPbvbb3NdlTV/5b9lj5OVRuVe35HVZ2iqotVdaqqdq7KOJxz9znn3nHOrXXOzRORJ0XkwCq/MKQVo7mf4Zx7WES+qPqrQSZiNPc/OOcWlHtovYi0qsq+UHkxmn/O/WoWl7kv21cDEblORC6v6j4KpSQKQEm8jlEi0kJEmovIKhG529umt4icKSJbi8g6ERkuIqKq24jIy5L4jb2RJK7YjVHVpv5BVLV52RdM80qO62Dhm0K+xXXukX+xmXtV7aSqS0RkmYh0F5E7s3plqIzYzD+qXZzm/iYRuU9Efs7mBRVCSRSAzrnfnHNjnHMrnXPLRGSIiBzibTbaOTfNObdCRK4RkVNUtaaI9BKRV5xzrzjnNjjnJorIRyLSLclx5jjnGjrn5qQbk6r2FZG9ReTWLF8eUojj3KN6xGnunXPvlv0JeFsR+YeIzMrJi0SF4jT/qF5xmXtV3VsSf+UbkcOXV21KogBU1Xqqer+qzlbVpSLytog0LJvsP/xQ7t+zRWQjSfTqtRCRk8uq/MWqulhEOonIVlmM5wQRGSoiR3l/GkKOxW3uUX3iOPdlrR+vicjT2ewH6cVx/lE94jD3qlpDRO4VkX7OuXVZvJyCKbqmxQpcJiJtRGQ/59zPqtpBRD4VES23zXbl/t1cEo27CyTxRTLaOXd2LgaiqkeKyIMicrRz7vNc7BMpxWbuUe3iOve1RGTHPOwXVlznH/kXh7mvL4m/8j2jqiIifxSfc1X1ZOfcO1nuP++K8QrgRqpap9xHLRHZTBI9AIvLGj2vS/K8XqraVlXricj1IvK8c269iDwhIseq6hGqWrNsn52TNJSmpapdJPHGj+7Ouf9W+RWiInGee1XVOiJSuyzXUdWNq/pCERHnue9Z1iukqtpCEn+OeqPKrxTJxHn+OffzK65zv0QS/YUdyj7++BPyXiLyQaYvshCKsQB8RRIT/8fHYEk0XNeVRHX/viT+BOMbLSKPSqJRs46IXCySeAefiBwvIleJyHxJ/HYwQJL835R9k1+uFTeEXiMiDUTklbLtlqvqq1V5kUgqznPfomxMf7zpZ5WIzMjs5SGFOM99WxGZIiLLJbEkzAwR4cpSbsV5/jn38yuWc+8Sfv7jo2xfIiK/OOfWVvG1Vit1jnUrAQAAQlKMVwABAACQBQpAAACAwFAAAgAABIYCEAAAIDAUgAAAAIFJuRC0qvIW4RLjnNP0WyUw/6WnsvPP3Jcezv2wce6Hq6K55wogAABAYCgAAQAAAkMBCAAAEBgKQAAAgMBQAAIAAASGAhAAACAwFIAAAACBoQAEAAAIDAUgAABAYCgAAQAAAkMBCAAAEBgKQAAAgMBQAAIAAASGAhAAACAwFIAAAACBqVXoAQD5dtddd5l88cUXmzxt2rTIc4455hiTZ8+enfuBAQCC9sYbb5isqiZ36dIlb8fmCiAAAEBgKAABAAACQwEIAAAQGHoAK7DZZpuZvOmmm5p89NFHm9y0aVOTb7/99sg+16xZk6PRIZWWLVua3KtXL5M3bNhg8i677BLZx84772wyPYDFoXXr1iZvtNFGJh988MEm33vvvZF9+F8fuTBu3DiTe/ToYfLatWtzfkxE5/+AAw4w+aabboo858ADD8zrmBC2O+64w2T/a/Lxxx+vtrFwBRAAACAwFIAAAACBoQAEAAAITJA9gH6P2MCBAyPb7L///ia3a9cuo2NstdVWkcf89eeQH/Pnzzf57bffNvm4446rzuEgh3bddVeT+/TpY/LJJ59sco0a9nfcrbfe2uRk/X7OuSxGmJz/NTdy5EiTL7nkEpOXLl2a8zGEqEGDBia/+eabJv/888+R52y55ZZptwEqa+jQoSafd955Jv/+++8m++sC5hNXAAEAAAJDAQgAABAYCkAAAIDAlGQPoL+Gm99f07NnT5Pr1q0b2Yd/P74ffvjB5GXLlpnsryV3yimnRPbprzk2ffr0yDbI3ooVK0xmDb/ScfPNN5vcrVu3Ao0kO7179zb54YcfNvm9996rzuEEy+/3S/YYPYDIRseOHU3216Z89913TX722WfzPqY/cAUQAAAgMBSAAAAAgaEABAAACExR9gD6azvdcsstJp966qkm+/f1rYyZM2eafMQRR5js/x3f7+dr0qRJZJ/JHkPuNWzY0OT27dsXZiDIuYkTJ5qcrgfw119/NdnvtfPXCRRJfy9g/96dhxxySMrtEV9+rzdKh3/f76uvvtrk0047LfKchQsXZnXMZPv01xD+9ttvTe7fv39Wx8wGVwABAAACQwEIAAAQGApAAACAwFAAAgAABKYo3wRy4oknmvzXv/41q/35TZkiIocddpjJ/kLQrVq1yuqYyJ969eqZ3Lx584z3sc8++5jsv8mHxaUL47777jN57NixKbf3b7Sei0V969evb/K0adNM3nrrrdPuwx/3Rx99lPW4kDnnXOSxOnXqFGAkyLUHHnjA5J122snktm3bRp7jL8qcqauuuiryWOPGjU0+++yzTZ46dWpWx8wGVwABAAACQwEIAAAQGApAAACAwBRlD+DJJ5+c0fazZs0y+cMPPzR54MCBkef4PX++XXbZJaMxoPr8+OOPJj/66KMmDx48OO0+/G0WL15s8t13312FkSFb69atMzndeZoP/qLwm2++ecb7mDt3rslr1qzJakzInb333tvk999/v0AjQTZWrlxpst/vmYtezw4dOpjcokWLyDb+wvJx6jHlCiAAAEBgKAABAAACQwEIAAAQmKLsAfTX0TnnnHNMfv31103+5ptvTPZvEF8VzZo1y3ofqB433HCDyZXpAQT+0KNHD5P97z9169bNeJ/XXnttVmNC5fg9o0uWLDG5QYMGkefsuOOOeR0T8sP/Pr/bbruZ/NVXX5lclfX3NtlkE5P99w/4a9CKRHtIn3/++YyPmy9cAQQAAAgMBSAAAEBgKAABAAACU5Q9gP46b4Xo6dp///2r/ZjIjRo17O89/jpNCEfPnj0jj11xxRUm+/f93mijjTI+zmeffWayf49i5Ie/fuc777xj8jHHHFONo0Eubbfddib7vbl+/+eFF15o8vz58zM+5u23326yvyaxX5uIiBx44IEZH6e6cAUQAAAgMBSAAAAAgaEABAAACExR9gBm6+KLLzbZX9unMvw1hnxTpkyJPPaf//wn4+Mg9/yeP/8ekYivli1bmnz66aeb3LVr14z216lTp8hjmX49LF261GS/h1BE5JVXXjF51apVGR0DCF27du1MfvHFF01u0qSJySNGjDD5rbfeyviY/fv3N7lPnz4ptx8yZEjGxygkrgACAAAEhgIQAAAgMBSAAAAAgSmJHkD//ntt27Y1+brrrjO5W7duafeZ6Vpx/vo/ffv2jWyzfv36tMcFkOD3/IiI/Otf/zK5efPm1TWcCvlryz3wwAMFGglyoXHjxoUeQnBq1bKlSK9evSLbPPzwwyan+xntr9V75ZVXmuyv6Sci0qhRI5P9df5U1eTHH3/c5Pvvvz+yzzjjCiAAAEBgKAABAAACQwEIAAAQGApAAACAwMT+TSDJbry+xx57mDxmzBiTt9pqK5P9RVf9N2wkW6D5yCOPNNl/o4nPb2I96aSTItvcddddJq9duzblPgFYfhO2nzPlN5KLpH/Dl++YY44x+aijjops8+qrr2Y2MBTMcccdV+ghBKdHjx4mP/TQQ5Ft/AXa/fP0m2++MXnvvfdOmY8//vjIMbbZZhuT/Vpi/vz5Jp955pmRfRQTrgACAAAEhgIQAAAgMBSAAAAAgYldD2Dt2rVN9nvxREReeOGFlPv4+9//bvKkSZNMfu+990z2F39M9pxki9KW17RpU5NvvvnmyDZz5swxeezYsSavWbMm5TGQG5ku8i0icvDBB5t8991353RMiJo2bVrksc6dO5vsLxg7YcIEk1evXp31OM466yyTL7rooqz3icJ48803Tfb7N1E9Tj31VJNHjRpl8u+//x55zuLFi03+y1/+YvKiRYtMvu2220w+5JBDTPZ7AkWiPcV+32GTJk1M/uGHH0z2vz+JiHz77beRx+KCK4AAAACBoQAEAAAIDAUgAABAYNT/G7f5pGrFn8wRf52/66+/3uQBAwak3Ye/xtbpp59ust874PfrvfLKK5F97rnnnib7a/YNGzbMZL9HMNkaQ75///vfJt9yyy0m+z0Nvs8++yztMXzOuUovnFYd818I69evNznVOVCR3Xff3eQvv/wyqzFVl8rOf6nOfVU0aNDA5N9++y3l9scee2zksTisA8i5L9K9e3eTn3vuucg2/rqxbdu2NXn27Nm5H1g1iNO57/fYt2jRwuQbb7wx8hy/TzAdf97uv/9+k/fff//Ic9L1APr++c9/mty7d+9MhlhtKpp7rgACAAAEhgIQAAAgMBSAAAAAgan2dQBr1qxp8g033GBy//79TV6xYkVkH1dccYXJTz/9tMl+z5+/3o+/hpt/b2ERkZkzZ5p8/vnnm+yvJ1W/fn2TDzjggMg+e/bsabJ/z8mJEydGnlOev+bQ9ttvn3J7JDdy5EiTzz333Iz3cc4555h8ySWXZDMkxNgRRxxR6CEgR9atW5d2G78PbOONN87XcII1btw4k/21ff2fdVXhr9mXbi1fEZHTTjvN5GRrkZY3d+7czAcWI1wBBAAACAwFIAAAQGAoAAEAAAJT7T2Afu+U3/O3cuVKk5P1Z73++usmd+zY0eS+ffuafNRRR5lct25dk/21B0Wiaw6l60lYunSpya+99lpkG/8xv9/Av7eh79JLL035eVTO9OnTCz0ESHQN0MMPP9xkf60wkegabfngf/+466678n5MVA+/9yzZ94Kdd97ZZL+/94ILLsj5uEKTj3PKX6/z5JNPNtnv0092j95nn3025+OKM64AAgAABIYCEAAAIDAUgAAAAIGhAAQAAAiMprrZcT5uCv3TTz+Z3LRpU5PXrFljcrIm3U022cTkVq1aZTSGwYMHm3zzzTdHtlm/fn1G+ywW3BA+6uuvv448tuOOO6Z8To0a9ncn/2swWYNxHBTyhvCdOnUy+eqrrzb5sMMOMznZQufZLhDbqFEjk7t16xbZZsSIESZvttlmKffpvzHFX+BdJLpwfCFw7kfdeeedkcf8NwE1a9bM5NWrV+dzSHlTyHO/Olx55ZUm+zeZmD9/vsn77LNPZB/FvrBzRSqae64AAgAABIYCEAAAIDAUgAAAAIGp9oWgf/75Z5P9HkD/xtvt27dPu89XXnnF5LffftvksWPHmjxr1iyTS7XfD5XzxRdfRB7bYYcdUj5nw4YN+RpOybr77rtNTndz9ssvvzzy2LJly7Iag99nuOeee0a2SdUXLSIyefJkk++77z6T49Dvh6rz53/t2rUFGglSadGihcl//etfTfbn8YEHHjC5VPv9MsEVQAAAgMBQAAIAAASGAhAAACAw1d4DePDBB5t8wgknmOz35Pz666+RfTzyyCMmL1q0yGR6NpAJvzdEROTYY48twEhQ3vnnn1+Q4/rfc1566SWT+/XrZ3KxrguH5OrXr2/y8ccfb/KLL75YncNBBSZOnGiy3xP4xBNPmHzdddflfUzFhiuAAAAAgaEABAAACAwFIAAAQGCq/V7AKCzuBxrl946IiIwfP97kXXbZxWRV+9/YunVrk7kXcFSHDh1Mvuiii0w+44wzcn3IyDysXLnS5HfeeSfyHL8ndNq0aTkfVyFw7kf9+OOPkcc233xzk/fYYw+Tk92fvhiU2r2A09379+STTzY55N5N7gUMAAAAEaEABAAACA4FIAAAQGDoAQwMfUBhi1MfkH/f7z59+ph84403Rp7j92f59/n21wYbN26cyf69yEPCuR/19NNPRx7z+32PO+44k2fPnp3XMeVLnM59VC96AAEAACAiFIAAAADBoQAEAAAIDD2AgaEPKGz0AYWLcz9snPvhogcQAAAAIkIBCAAAEBwKQAAAgMBQAAIAAASGAhAAACAwFIAAAACBoQAEAAAIDAUgAABAYCgAAQAAAkMBCAAAEBgKQAAAgMBQAAIAAARGneO+zwAAACHhCiAAAEBgKAABAAACQwEIAAAQGApAAACAwFAAAgAABIYCEAAAIDAUgAAAAIGhAAQAAAgMBSAAAEBgKAABAAACQwEIAAAQGApAAACAwFAAAgAABIYCEAAAIDAUgAAAAIGhAAQAAAgMBSAAAEBgKAABAAACQwEIAAAQGApAAACAwFAAAgAABIYCEAAAIDAUgAAAAIGhAAQAAAhMEAWgqk5W1b9W93NReMx9uJj7sDH/4WLuK6eoCkBVnaWqXQs9joqoag9VnaGqS1T1V1V9TFXrF3pcpaAI5r6Pqq5X1eXlPjoXelyloAjmnvM+j+I+/yIiqrqDqo5X1WWqukBVhxV6TKUg7nOvqu1UdULZnLtCjydTRVUAFoH3RORA51wDEdlBRGqJyI2FHRKq0X+cc5uW+5hc6AGhWnDeB0xVa4vIRBGZJCJbisi2IvJEQQeF6vK7iDwrImcVeiBVURIFoKpuXvbb13xVXVT27229zXZU1f+W/ZY+TlUblXt+R1WdoqqLVXVqVa/cOOd+cM4tKPfQehFpVZV9oXLiMveofnGZe877wojL/ItIHxH50Tl3u3NuhXNutXPuf1XcFyohLnPvnJvhnHtYRL6o+qspnJIoACXxOkaJSAsRaS4iq0Tkbm+b3iJypohsLSLrRGS4iIiqbiMiL0viN/ZGItJfRMaoalP/IKravOwLpnlFA1HVTqq6RESWiUh3Ebkzq1eGdGIz9yKyR9mfAr5W1WtUtVZ2Lw1pxGbuOe8LIi7z31FEZqnqq2Xn/2RV3S3rV4dU4jL3xc05VzQfIjJLRLpWYrsOIrKoXJ4sIkPL5bYislZEaorIQBEZ7T1/goicUe65f63CWLcRkcEi0rrQ/2+l8BH3uZfEn/62l8Q3pt1E5EsRubLQ/2+l8BH3uff2wXkf2PyLyOuS+FPgUSJSW0QGiMh3IlK70P93xf4R97kv9/xWIuIK/f+V6UdJXAFU1Xqqer+qzlbVpSLytog0VNWa5Tb7ody/Z4vIRiLSRBK/QZxcVuUvVtXFItJJRLbKZkzOuXki8pqIPJ3NfpBaXObeOfedc+5759wG59znInK9iPy5ii8LlRCXuS+P8776xGj+V4nIu865V51za0XkVhFpLCK7VGFfqIQYzX1RK5U/UV0mIm1EZD/n3M+q2kFEPhURLbfNduX+3VwSv7EtkMQXyWjn3Nl5GFctEdkxD/vF/4nr3DtvDMi9uM495331iMv8/09EDszBflB5cZn7olaMVwA3UtU65T5qichmkvgtbHFZo+d1SZ7XS1Xbqmo9SVyded45t14S79Y6VlWPUNWaZfvsnKShNC1V7VnWM6Cq2kJEhojIG1V+pfDFee6PUtVmZf/eWUSuEZFxVXydiIrz3HPe519s579sXx1VtWvZFahLJFFofFWFfSEqtnNfds7XkcSf/qVsXxtX9YVWt2IsAF+RxMT/8TFYEg3XdSVx0r0viT/B+EaLyKMi8rOI1BGRi0US7+ATkeNF5CoRmS+J3w4GSJL/m7Jv8su14obQtiIyRUSWS2JpiBkiEvxvGTkU57k/VET+p6orysb5gojclPlLRAXiPPec9/kX2/l3zs0QkV4iMlJEFpXt97iyPwcje7Gde0n8OXmV/N+7gFdJ4vwvClrWwAgAAIBAFOMVQAAAAGSBAhAAACAwFIAAAACBoQAEAAAITMp1AFWVd4iUGOdcpdemY/5LT2Xnn7kvPZz7YePcD1dFc88VQAAAgMBQAAIAAASGAhAAACAwFIAAAACBoQAEAAAIDAUgAABAYCgAAQAAApNyHUAAAELWunVrk1977TWTa9asaXKLFi3yPiYgF7gCCAAAEBgKQAAAgMBQAAIAAASGAhAAACAwvAkEAIAyI0aMMPnUU081uVGjRiaPHz8+72MC8oErgAAAAIGhAAQAAAgMBSAAAEBgSrIHsG3btiYfc8wxJp9zzjkmf/jhh5F9fPrppymPceedd5q8du3aDEYIAKhuzZo1M/mFF16IbNOxY0eTnXMmT5s2zeSzzjorR6MDqhdXAAEAAAJDAQgAABAYCkAAAIDAqN/fYD6pWvEnY+Tcc881+dZbbzV50003zfkxu3TpYvKbb76Z82Pkg3NOK7ttscw/Kq+y81+VuffPM3/9tNWrV5u81157mbzZZpuZ3LNnz8gxJk+ebPK8efMyHabx888/Rx4bN26cyR999FFWx4iLEM/91q1bm+z/bOjWrVvkOar2v+mKK64w2f96KLXv/cU69/68PfXUUyb7c+2/V0BEZO7cubkfWAxUNPdcAQQAAAgMBSAAAEBgKAABAAACUxI9gP69Gb/66iuTt9hii5wfc/HixSb7/U6vv/56zo+ZCyH2AeH/5LMPaNiwYSb3798/013EwoYNG0z+8ssvTfZ7i/w8a9asvIwrWyGe+/6afu+++27a5/i9ZL169TLZn+9iUeo9gPXq1TN5xowZJm+zzTYm++sBi4g89NBDuR9YDNADCAAAABGhAAQAAAgOBSAAAEBgSuJewAsXLjT5uuuuM/m2224z2e8VmDNnTmSfzZs3T3nMhg0bmnzkkUeaHNceQBROixYtTK5bt67Jp512msnnn39+yv29/PLLkcf69u1bxdFl76STTsrq+b/99pvJ//vf/7Lan0i0D6hNmzYm++exiMgee+xhcrt27UweMmSIyf4449oDGAJ/3b9//vOfJvv9fcn4X8f+upCIp5UrV5o8c+ZMk/0ewKZNm+Z9THHHFUAAAIDAUAACAAAEhgIQAAAgMCXRA+gbOXKkyeedd57J7du3N3np0qVZH/Puu+/Oeh8oXl27djU5WT+c3+PXoEEDk1OtyZmMv8ZZoR1xxBEm+/1YX3/9dcrn+z08P/30U24GloJ//2ERkc8//9zkdP3Axx13nMnJejNRPU4//XST/bl75ZVXTPZ/Nohkf39pxMM999xjcufOnU3eZZddqnE08cQVQAAAgMBQAAIAAASGAhAAACAwFIAAAACB0VSN58V6U2jfn//8Z5Ovvvpqkzt06JD1MfyG0unTp2e9z3wI8YbwueDfJHy33XYzeZ999sl4n8uWLTP5ySefNPnDDz802b8J/erVqzM+ZqnfED5T/htzRKLz4FuzZo3JBx10kMkfffRR9gPLg1I896dMmWKy/738xx9/NNlfsP+bb77Jy7jiKLRzf7vttjN59uzZJq9duzbynO23397k6ngjWnWoaO65AggAABAYCkAAAIDAUAACAAAEpiQXgvY9//zzJr/77rsmv/7665Hn+D1e6dx4440m+32HiK/GjRtHHrv55ptNPvPMM01euHChyR9//LHJQ4cOjexz2rRpJq9atcrkOXPmpB8sMlK7dm2Thw8fbnLv3r0z3uf+++9v8meffZbxPlA1xx9/vMn77befyX5P+3PPPWdyVfpmURpUbRuc/71BJLqo+/3335/XMRUaVwABAAACQwEIAAAQGApAAACAwATRA9izZ0+T27dvb3K7du2yPobfV4jicc0110QeO+uss0weMWKEyf5aksuXL8/9wJCxP/3pTyaffvrpJvfp0yftPn7//XeTL774YpPjusZnqWnYsGHkMX/NxXQWLVpk8ty5c7MZkoiI9OvXz2R/vblk+vfvn/VxkZ1Uax7/IVlfYCnjCiAAAEBgKAABAAACQwEIAAAQmJLoAdx5551NfvHFF01u1aqVybVq5f5l/+tf/8r5PlE19erVM3ngwIEm+31hl1xySWQfb775pskTJkwwmfXE4mHfffc12V/Ts2bNmhnv0+8V8tdnXL9+fcb7ROaS/T/vtddeJteoYa9hbNiwweS333474+NeeumlKT9/0UUXmdyiRYu0+7zssstM3nbbbU2eN29eJUcH5A5XAAEAAAJDAQgAABAYCkAAAIDAlEQP4C677GLy9ttvb3I+ev58ft+I3yeC6jNo0CCT/R7AZ5991uRk94Kmx684nHLKKSZXpefP568F9vLLL5v80UcfmfzSSy+Z7Pcgi0TvA430DjnkkMhj/jqAfs+f36+5YMGClMfo0KFD2mP494f1rVixwuRkaw22adPGZP/+9D169DB59uzZKY8J5AJXAAEAAAJDAQgAABAYCkAAAIDAlEQPoN9zc/nll5t8yy23mFynTp2cj2GrrbbK+T5RNVdeeaXJ/rpuTz31lMn0+xWvF154wWS/H3ifffYxuUmTJlkfc++9906Zr7vuushz7rzzTpOHDRtm8q+//pr1uIrdZpttZrLfy53Mjz/+aPLo0aNN/uabb0xu3bq1yQMGDIjs8/jjjzfZ7yP0e4Zvu+02kxs0aBDZ56RJk9Jug/xSVZMrc2/gUscVQAAAgMBQAAIAAASGAhAAACAwFIAAAACBKYk3gfiGDx9u8syZM01u2LBh2n34i0fffffdJtevX79qg0Pe/fe//zXZb9L353LVqlWRfUycODH3A0POTZkyxeSjjz7a5ObNm5vsvwmkWbNmkX2edNJJJp955pkm+83kvho1or9X/+1vfzN5r732MvnQQw812V/gOASdOnUy+Y477kj7nAcffNDk66+/3mR/fm+99VaTu3XrFtnnsmXLTPYXju/fv7/JO+20k8kjR45Mu8833njDZBZ+zj/e9BHFFUAAAIDAUAACAAAEhgIQAAAgMJrq7+KqGuwfzf0+n8GDB5t87bXXmvztt9+a7Pf0iMSjz8M5l7qBqZw4zP9+++0XeezTTz81ee3atSY3atTI5Isvvtjka665xuTly5enPe706dPTD7YIVHb+4zD3cdGzZ0+TL7roIpP33XffrI9xxRVXmOwvFJ0LcT/3Bw4caPKQIUPSPsfv1fa99957Jif7fuLzv3e/9dZbJnfs2NHkd999N+0+/YXA/T7C6hDaub/ddtuZXJmfv3/6059M9ue+WFU091wBBAAACAwFIAAAQGAoAAEAAAJTkusA5kLt2rVN9nv+fL///rvJ69evz/mYStFWW21l8vjx403213ETEbn00ktNfuKJJ0xeuHChyf66f34P4Kabbho5ht9HiHA9+eSTJj/zzDMm//vf/zb54IMPzvgYrVq1ynxgJcZfnzXZeovjxo1LuY8OHTqY3LJly5T7vOyyyyL78Pu+WrdubfI///nPjPfp9wAinvxe/lLHFUAAAIDAUAACAAAEhgIQAAAgMPQAVuDGG2/MaPuHH37Y5Llz5+ZyOCXrk08+Mdm/x7K/NphItOcvnX79+qX8vN/DJSIybdq0jI6BcKxbt87kjz/+2OSq9AB+/fXXWY2pFCVbozbT+7n691T2n7/77rtHnjNnzhyT69SpY/L3339v8kEHHWTykiVLMhojUChcAQQAAAgMBSAAAEBgKAABAAACU/B7ATdu3NjkUaNGmfzUU09FnpPssWz4a9GJRO/96vem+XbccUeTv/vuu+wHlgdxux/olVdeafKgQYNMrlu3bsb7nDlzpsk77bSTyf49Ibt37x7Zh9+bWCqK6X6gyc7Ls88+22T/PH322WfzOiYRkZo1a5o8YcIEk7t06ZJ2H34fof+cytxfNlNxO/d9VbnHbqdOnUz21wEcOnSoycnW/PT56/otWLDA5D59+pj86quvpt1nHBTTuZ8LVbkXsP+zolTWBeRewAAAABARCkAAAIDgUAACAAAEhgIQAAAgMAVfCHr48OEmH3vssSb7N+IWEfnxxx9NnjdvnsnffPONyXvttVfKfV5++eWRY6R708dtt92WckyonJtvvtnk33//3eQ99tgj8pyuXbum3Ofmm29u8ssvv2xy//79Tfa/XlAYW265pcmvvfZaZJvddtvNZH+u86FZs2Ym/+1vfzO5Mm/68H311Vcm5+NNH8XGP/dXrlwZ2aZevXomv/feeyZnulB0MsuWLTPZf2NRsbzpA5nr1q2bySNGjCjQSKoHVwABAAACQwEIAAAQGApAAACAwBS8B9D/G/v2229v8v777x95zuTJk02eNWuWyV9++aXJ/s26N9tss7Tj8ntJ/AVnr7vuOpNXr16ddp9I79Zbby30EFAgd955p8l+v18y/veLGTNmmLxq1aqUz0+20LjfE+z3/KX7/uEvJCwS7Su7+OKLU+4jRB9//LHJp512WmQbfy46d+6c0TEee+wxkz///PPINp9++qnJb731VkbHQDz88ssvJn/xxRcm77rrrtU5nFjiCiAAAEBgKAABAAACQwEIAAAQGE21blIhbgrtr6+XbI22e++9N+/jWLhwocmNGzfO+zGrQ9xvCI/8ivMN4c8++2yT77///oz34fdvLVmyJOX2DRo0iDyWbO3JTCxfvjzy2IknnmjyG2+8kdUxqoJzP2xxPverw4cffmiyvz6wiMj48eNNPu644/I6pupS0dxzBRAAACAwFIAAAACBoQAEAAAITMHXAfRddtllJm+88caRbTbddNOU+/B7eJKtJ1Vesj6hww47LOVzAOTWxIkTTX766acj2/To0SPlPrLt36uMdevWmeyvXzhmzJjIcz744IN8DglAGp999pnJyXoA09UWpYYrgAAAAIGhAAQAAAgMBSAAAEBgYrcOIPKLtcDCVkxrgSXr//XX0+vSpYvJX3/9tcnp1vHy7/GdzKRJk1I+x+8tiivO/bAV07mfDy1btjT5qaeeimzj3yt65MiR+RxStWEdQAAAAIgIBSAAAEBwKAABAAACQw9gYOgDClvofUAh49wPG+d+uOgBBAAAgIhQAAIAAASHAhAAACAwFIAAAACBoQAEAAAIDAUgAABAYCgAAQAAAkMBCAAAEBgKQAAAgMBQAAIAAASGAhAAACAwFIAAAACBUee47zMAAEBIuAIIAAAQGApAAACAwFAAAgAABIYCEAAAIDAUgAAAAIGhAAQAAAgMBSAAAEBgKAABAAACQwEIAAAQGApAAACAwFAAAgAABIYCEAAAIDAUgAAAAIGhAAQAAAgMBSAAAEBgKAABAAACQwEIAAAQGApAAACAwFAAAgAABIYCEAAAIDAUgAAAAIGhAAQAAAgMBSAAAEBgKAABAAACE0QBqKqTVfWv1f1cFB5zHy7mPmzMf7iY+8opqgJQVWepatdCj6MiqjpSVZeX+1ijqssKPa5SUARzf4aqfqyqS1V1rqoOU9VahR5XKSiCuVdVvVFV56nqkrIfILsWelylIu7zLyKiqjuo6nhVXaaqC1R1WKHHVAriPvequrGq3qGqP6rqIlW9V1U3KvS4KquoCsC4c86d55zb9I8PEXlKRJ4r9LhQLeqJyCUi0kRE9hORQ0WkfyEHhGpzsoicKSIHiUgjEfmPiIwu6IhQbVS1tohMFJFJIrKliGwrIk8UdFCoLleIyN4i0k5EWovIniIyqKAjykBJFICqunnZb1/zy6rw8aq6rbfZjqr637Lf0MepaqNyz++oqlNUdbGqTlXVzjkY0yYi0l1EHst2X6hYXObeOXefc+4d59xa59w8EXlSRA6s8gtDWnGZexHZXkTedc5955xbL4kf/m2ruC9UUozmv4+I/Oicu905t8I5t9o5978q7guVEKO5P1ZEhjvnFjrn5ovIcEn8MlgUSqIAlMTrGCUiLUSkuYisEpG7vW16S2JithaRdZKYKFHVbUTkZRG5URK/vfcXkTGq2tQ/iKo2L/uCaV6JMXUXkfki8nZVXhAqLY5zLyJysIh8kfGrQSbiMvdPi0grVW1d9uefM0TktSxfG9KLy/x3FJFZqvqqJv78O1lVd8v61SGVuMy9ln2Uz9uqaoMqvq7q5Zwrmg8RmSUiXSuxXQcRWVQuTxaRoeVyWxFZKyI1RWSgiIz2nj9BRM4o99y/VmGsb4jI4EL/n5XKR5HNfV8RmSsiTQr9/1YKH3GfexGpLSJ3iYiTxA+a70Vk+0L/v5XKRxHM/+si8ruIHFX2tTBARL4TkdqF/r8r9o8imPsbReQ9EWkqiT//f1D2fWCrQv/fVeajJK4Aqmo9Vb1fVWer6lJJXHVrqKo1y232Q7l/zxaRjSTRr9VCRE4uq/IXq+piEekkIltlMZ7tROQQEXm8qvtA5cRw7k8QkaEicpRzbkFV94P0YjT314nIPiKynYjUEZG/i8gkVa1XhX2hkmI0/6sk0QLwqnNurYjcKiKNRWSXKuwLlRCjuR8iIp+KyGciMkVExkril4Ffq7CvalcSBaCIXCYibURkP+dcfUn8+U3EXprdrty/m0tikhZI4otktHOuYbmPTZxzQ7MYT28RmeKc+y6LfaByYjP3qnqkiDwoIsc65z6vyj6QkbjMfXsRecY5N9c5t84596iIbC70AeZbXOb/f5K46oPqE4u5d86tcs5d6Jzbxjm3g4j8JiIfu0QvcOwVYwG4karWKfdRS0Q2k8RvYYvLGj2vS/K8Xqratuy38utF5Hn3fw3bx6rqEapas2yfnZM0lGait4g8msXzkVxs515Vu0jijR/dnXP/rfIrREViO/ci8qEkrig0U9Uaqnq6JK42fFOlV4pk4jz/T4hIR1XtWnYF6hJJFBpfVWFfiIrt3KvqNqq6tSZ0FJFrKhhLLBVjAfiKJCb+j4/BInKniNSVxEn3viRvwB4tiaLsZ0n8meZiERHn3A8icryIXCWJN238IIkejsj/TVlD6PIUDaGiqvtLYhkAln/JvTjP/TUi0kBEXtH/Wwfy1aq8SCQV57m/RUSmSuLPQItF5FJJ/CKwOLOXiBRiO//OuRki0ktERorIorL9Hlf252BkL7ZzLyI7SuJPvyskseLHFc651zN/iYWhZY2MAAAACEQxXgEEAABAFigAAQAAAkMBCAAAEBgKQAAAgMDUSvVJVeUdIiXGOafpt0pg/ktPZeefuS89nPth49wPV0VzzxVAAACAwFAAAgAABIYCEAAAIDAUgAAAAIGhAAQAAAgMBSAAAEBgKAABAAACQwEIAAAQGApAAACAwFAAAgAABIYCEAAAIDAUgAAAAIGpVegBAAAQVzvssIPJN998s8knnniiybvvvntkH9OnT8/9wIAscQUQAAAgMBSAAAAAgaEABAAACAw9gAAAlDnggANMfu2110yeP3++yffcc4/Jv/zyS34GBuQYVwABAAACQwEIAAAQGApAAACAwNADiJJz+umnm3z44Yeb3KFDB5PbtGmTdp/vv/++yccee6zJS5YsyWCEKGWbbLJJ5LHJkyebvPXWW5t84IEHmjxr1qxcDwtJHH300ZHHnn/+eZNHjhxp8tVXX23yypUrcz8woBpwBRAAACAwFIAAAACBoQAEAAAIjDrnKv6kasWfRFFyzmllt43r/Ddp0sTkhx56yGS/P2/x4sUmT5kyJe0xOnfubLLf1+Xf27Nt27Zp9xkHlZ3/uM59dfD785o2bZpy+0WLFpn8pz/9KbLNqFGjTJ4xY4bJ++67r8nLli1LO85MlcK5n61WrVqZPHXq1Mg277zzjsndunUzecOGDbkfWDXg3A9XRXPPFUAAAIDAUAACAAAEhgIQAAAgMKwDWIHLLrvM5Nq1a5u8yy67mNyzZ8+0+/T7xnbdddcqji5s/r05W7ZsafKwYcNM/sc//mHywoUL0x5j5513Nvm///2vya1btzb52muvNfn6669PewzkXrt27Uy++OKLTW7RokXaffhz27x585TbDx061ORk/aCqtgVn3rx5JvvfX5AbderUMdnvF/78888jzznllFNMLtaeP1iNGjUy+dRTT41sc9VVV5ns9wP7Bg0aZPLNN99cxdEVBlcAAQAAAkMBCAAAEBgKQAAAgMAEsQ7gIYccYrLfJ+R/XkTkxBNPNNnv4akKv5fkm2++Mbk61pIrtrXADjvssMhjfg/gs88+a/Jpp52W83H4PX1+78fs2bNN3n777XM+hlwo9bXA/J6/O+64I+N9rFmzxuTnnnvO5C5dupicrk9IJPr9o3fv3iY/8cQTmQyxSort3M8Fv//3wgsvNHmnnXaKPGfu3Ll5HVOhlPq57+vYsaPJ/vcCf+1NEZFU9VBljB49OvJY3759s9pnLrAOIAAAAESEAhAAACA4FIAAAACBoQAEAAAITOwXgt5qq60ijz311FMm77DDDin30aBBA5M32WQTk5O9wePjjz82ec8990x5jMqoUcPW2/44EFWrVvRL1H/zzNNPP533cTz//PMm+28C8RecrV+/fmQfS5cuzf3AAjd48GCTBwwYkHL7xx57zOT58+dHtrn11ltTbtOhQweTJ0yYYHKTJk0i+/T34X89ITc23nhjk3v16mXy5MmTTS7VN3yEyD/vHnzwQZP9mzckO/fHjh1r8rhx40z237x18sknm+y/8UQkusj72rVrI9sUClcAAQAAAkMBCAAAEBgKQAAAgMDErgewa9euJvt/xxcR2W677XJ6zGQLMC9YsMBkv7/AX/x11KhRJm+77bZpj/vll19WdojBevPNNyOP7bHHHiavXLky7+PwFwf2NWvWzOS//OUvkW1GjhyZ0zEh2kdbt25dk/0Fuq+++mqTf/rpp7THaNWqlcn+DeObNm1q8ooVKyL78HsVV69enfa4yNzll19u8qabbmqyP/8oHX6/nt/z9/rrr5vcrVu3jI8xc+ZMk/16JdnPfX8cU6dOzfi4+cIVQAAAgMBQAAIAAASGAhAAACAwsesB9Hs4qtLv5/drDRw40OT333/f5BkzZqTd52+//WZyv379TK5Mz9+sWbNMPv3009M+J3Rx6ZX67rvvTP7iiy9M3nXXXU1OdpN55J6/nt6RRx5pst/fO3ToUJMvuOCCyD79dUNvv/12k48++miTFy5caPKQIUMi+7zvvvsijyH3Dj/8cJPfe+89kz/55JPqHA6q0apVq1J+3u8RzIdka7367yeIE64AAgAABIYCEAAAIDAUgAAAAIEpeA+g37OR7F566cyZM8dkv7fO7wPJhcr0/Pn8HoQ49wbA+v33301et25dgUaC8j777DOT/f5evwewS5cuJh922GGRfd5xxx0mN2/ePOUY/v73v5s8YsSIlNsjdzp16mSy//Njt912y/oYnTt3Ntm/h6zfD4zCUNWUedGiRSb7928XEdlxxx1N7tOnj8l77bWXyT///LPJp512WmSf8+bNSz7gGOAKIAAAQGAoAAEAAAJDAQgAABCYgvcAXnbZZSbXq1cv7XOmTJlist+Dk4uev80339xkf32xgw8+OOXz/TGKiLzyyitZjwuFsfHGG5ucrH+kvGXLluVzOCjjr/mZbB2u8vx7eI8ZMyayjd875Jwz+eGHHzZ57Nix6YaJPOnVq5fJX331lcnff/99yuf7PV4iIrfddpvJ/s8C/2uuf//+Jt9zzz0pj4n88Ndi9c/bv/3tbyb7tYdItMfP16NHD5P9dUiLDVcAAQAAAkMBCAAAEBgKQAAAgMAUvAfwgQceMLlJkyYmL1myJPKcv/zlLyb7a/HkwnnnnWfyDTfckHJ7fy2oU045JbJNPsaJ6tGyZUuT27Rpk3L71157LeNj+F/77du3N3n//fc3+bnnnovsozL3tS5ls2fPzvk+/d7dW2+91eQffvgh58dE5Zx55pkm+z8b/H692rVrm3zddddF9nnuueeaPGHCBJO7detm8qhRo0z+9ttvI/usyvcDZOa3334zebPNNjN57733Ntnv9RWJ9g2uXLnS5C+//DKbIcYOVwABAAACQwEIAAAQGApAAACAwFAAAgAABKbgbwLxF2JNtjBrvh177LGRx6699tqUz1m3bp3JI0eONJk3fBQPf5FnEZFtt93W5AMOOCCjffpfDyIiH3/8scl77rmnyY0aNTJ5u+22M9lfXLpVq1aRYyRb2LaU1axZ0+SDDjrI5GSN3um8/PLLJif7/oDC8Bf7rVXL/gjzvy/7/HMu2Zsz0i3u+8wzz5jcqVMnk6+88srIc3gTSP75XxsdO3Y02f+e7s9jMi+88ILJvAkEAAAARY0CEAAAIDAUgAAAAIFRf+FD80nVij9ZQtavXx95LNX/i4jIBRdcYLK/oHVcOecq3RQVh/mvW7du5LEtttjCZL+vx+/96NKlS8pj1KlTJ/KY30+SqWRfU3Pnzk35nEcffdRkvxdtwYIFJs+aNSvjcVV2/uMw95XhL4Z90kknZb1P///9uOOOy3qfcVBs534yhx56qMkTJ040uW3btiZPnz7dZH9xYH9haJHogsLp+Mf8/PPPI9v4vaqFUGrnfqbatWtn8tSpUyPb+D/3/bn9+uuvcz+walDR3HMFEAAAIDAUgAAAAIGhAAQAAAhMwdcBLISbbrrJ5Bo1onXwhg0bUu7jrbfeyumYQuX3+A0ePNjkZGuw7bzzzlkdc+nSpSb76+uJRNcT89cb8z300EMmJ1sH8JNPPqnsECEiW2+9deSxvn37mty9e3eT/R4e///c7/vx9ycS7TFF8Zg3b17Kzyc717OVrrcX8bDbbruZXJWf+6WGK4AAAACBoQAEAAAIDAUgAABAYILoAfTXetpjjz1MTvZ3f7+XqF+/fibPnDkzR6ML29ixY00+7LDDTF6zZk3kOf46bd9//73J48aNS7kPf/28ZD08/vphrVu3Nvm7774z+W9/+5vJy5cvj+wTmfHXfBMRuf7661M+Z9CgQSbffffdJp9wwgkmJ+sBLLX7fZYS/97OVbnXc64dcsghJuejzxDZW7VqlcnJfu5PnjzZ5LVr1+ZzSAXHFUAAAIDAUAACAAAEhgIQAAAgMCXZA1ivXj2Te/XqZbLfZ5bMU089ZfKTTz5pcmjrBeXL4YcfbrLfz5fs3q6fffZZVsf01/S75ZZbIttss802Jv/6668mn3LKKSbT85e9zp07mzx8+PC0z/Hv0/vvf//b5C233NLka6+9Nu0+q3KPZVQPvzc73T3b82GjjTYy+bzzzjN59OjR1TkcVMBfL/ass84yef78+ZHn3HfffSaX+vcCrgACAAAEhgIQAAAgMBSAAAAAgaEABAAACExJvAlks802M/nBBx80+c9//nPK51966aWRx/wFZHnTR374TdyLFy82edq0aVkfo06dOiY/99xzJh999NGR5/iLR/fo0cPkTz75JOtxwfLfnNWgQYPINm+99ZbJ48ePN9lv0D/mmGNS7jPZQsLJmsMRD/4i3T/99JPJ/hv+/Kb+qvC/pvx9tmzZ0uQzzjgj62Mic/65PWHCBJP9N/YNHDgwso/nn38+9wOLMa4AAgAABIYCEAAAIDAUgAAAAIEpiR5A/2/76Xr+vv32W5Mrs+As8uPrr782uUOHDiY/8MADkec0btzY5KlTp5r83XffmTxgwACT27RpY/IHH3wQOcb5559vcraLTyM9v8822SK//mN+f9YJJ5xg8l133WXyokWLTH7ooYcix8hF3xjyw+/5u+mmm0y+7bbbUj7fX9B/hx12iGzTvn17k6+66iqTV69ebbK/mP2CBQtSjgH5MWzYMJP9usC/uUO6r5UQcAUQAAAgMBSAAAAAgaEABAAACExR9gD6N3m+7LLLUm7v95kdddRROR8TqsafyxtuuMHk/v37R55To4b9veXII49MeYx//etfJvtfL6+99lracSL/tthii7Tb+Gv0TZw40eSDDjoo5fP79u1r8ksvvVTJ0SGO7rnnnpSf9/u8/PVdk1m2bJnJfo/4jTfeaPLatWvT7hO517VrV5P9NSBXrVplcmhr/FUGVwABAAACQwEIAAAQGApAAACAwGiytbb+/0+qVvzJAvLXcjr11FNTbn/RRReZHPI6X8656M1PKxDX+UfVVXb+CzH3l1xyicmVWafLv5fvwoULTfZ7xIYOHWqy3ydUyjj3wxbnc78y/Hsuf/zxxyb793z3ewJffPHFvIyrGFQ091wBBAAACAwFIAAAQGAoAAEAAAIT+3UAd91118hj9evXT/kc//6xkyZNyumYAOTeY489ZnLt2rUj21xzzTUmf/TRRyb7az7ecccdORodgOpSt27dyGP++q0NGjQwecyYMSaH3PNXWVwBBAAACAwFIAAAQGAoAAEAAAIT+3UAb7nllshjfi/A7NmzTe7WrZvJM2bMyP3AihRrgYWt2NcCQ9Vx7oetmM79888/P/KYfx/nKVOmmOzfG3jNmjW5H1iRYh1AAAAAiAgFIAAAQHAoAAEAAAJDAQgAABCY2L8J5NBDD408NmHCBJO7d+9u8rhx4/I6pmJGI3jYiqkRHLnFuR+2OJ/7++67r8n+os4iIo888ojJDz74oMlz587N/cBKBG8CAQAAgIhQAAIAAASHAhAAACAwse8BRG7RBxS2OPcBIb8498PGuR8uegABAAAgIhSAAAAAwaEABAAACEzKHkAAAACUHq4AAgAABIYCEAAAIDAUgAAAAIGhAAQAAAgMBSAAAEBgKAABAAAC8/8BcIM+nGW/5ZQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 648x648 with 20 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display 20 images with theirs labels \n",
    "num_images=20\n",
    "\n",
    "fig, axes = plt.subplots(nrows=4, ncols=num_images//4, figsize=(9, 9))\n",
    "\n",
    "# Display num_images//nrows images per row, i is the index f current image being plotted \n",
    "for i in range(num_images):\n",
    "  # row index of current image in the subplot grid \n",
    "  i_row = i // (num_images//4)\n",
    "  # column index of current image in the subplot grid\n",
    "  i_col = i % (num_images//4)\n",
    "  ax = axes[i_row, i_col]\n",
    "  ax.imshow(images[i].reshape(28,28), cmap='gray')\n",
    "  ax.set_title(\"Label: {}\".format(labels[i]))\n",
    "  ax.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ffb776b",
   "metadata": {},
   "source": [
    "## 3. Implement k-Nearest Neighbor Algorithm:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6852fcf2",
   "metadata": {},
   "source": [
    "The k-Nearest Neighbors (KNN) algorithm is a simple yet powerful classification and regression technique in machine learning. It operates based on the assumption that similar data points tend to share similar outcomes. In a nutshell, when tasked with classifying a new data point, KNN looks at its `k` nearest neighbors in the training data and assigns the new point the class label that the majority of its neighbors possess.\n",
    "\n",
    "We can implement this algorithm as follows:\n",
    "\n",
    "1. Calculate the distance between the new data point and all existing data points in the training dataset.\n",
    "2. Select the `k` data points with the shortest distances.\n",
    "3. Determine the most frequent class label among these `k` neighbors.\n",
    "4. Assign the new data point the class label that appeared most frequently.\n",
    "\n",
    "**Advantages of KNN:** \n",
    "\n",
    "- Easy to understand and implement\n",
    "- Non-parametric: KNN doesn't make assumptions about the underlying data distribution, making it suitable for a wide range of data types and shapes of decision boundaries.\n",
    "- Adaptability: KNN can adapt to changes in data without needing to retrain the entire model, making it useful for dynamic or evolving datasets.\n",
    "- Flexibility: KNN can be used for both classification and regression tasks.\n",
    "- Interpretable: The results of KNN can be easily interpreted and visualized, aiding in understanding the decisions made by the model.\n",
    "\n",
    "**Disadvantages of KNN:**\n",
    "\n",
    "- Computational Complexity: KNN's prediction time can increase significantly as the dataset grows, since it requires calculating distances for every point in the training set.\n",
    "- Sensitive to Irrelevant Features: If the dataset has many irrelevant features, the distance calculation can be skewed, leading to poor predictions.\n",
    "- Choosing `k`: Selecting the right value for `k` is crucial. A small `k` can make the model sensitive to noise, while a large `k` may lead to oversmoothing.\n",
    "- Imbalanced Data: In datasets with imbalanced class distributions, KNN might favor the majority class due to the influence of nearby neighbors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a8eb88d",
   "metadata": {},
   "source": [
    "### 3.1. Distance Function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bbc1a44",
   "metadata": {},
   "source": [
    "To use k-NN classification method, it is necessary to measure distance between the training dataset and the selecting testing dataset. There are various ways to measure distance.\n",
    "\n",
    "\n",
    "1. **$L_p$ distance**: The $L_p$ distance between two points $\\mathbf{x}=(x_1, x_2, ..., x_n)$ and $\\mathbf{y}=(y_1, y_2, ..., y_n)$ is defined by \n",
    "      $$L_p(\\mathbf{x, y})=\\sqrt[p]{\\sum_{i=1}^{n} (x_i-y_i)^p}$$\n",
    "The $L_p$ distance is a general form of distance.\n",
    "\n",
    "2. **Manhattan distance or $L_1$ distance**: This distance is the gridwise measure in the space between two points $\\mathbf{x}=(x_1, x_2, ..., x_n)$ and $\\mathbf{y}=(y_1, y_2, ..., y_n)$ which is defined by\n",
    "$$L_1(\\mathbf{x, y})=\\sum_{i=1}^{n} |x_i-y_i|$$\n",
    "    \n",
    "3. **Euclidean distance or $L_2$ distance**:  It measures the distance between two points namely $\\mathbf{x}=(x_1, x_2, ..., x_n)$ and $\\mathbf{y}=(y_1, y_2, ..., y_n)$ in Euclidean space,  $\\mathbb{R}^n$ which is basically the length of a line segment between the two points. So,\n",
    "$$L_2(\\mathbf{x, y})=\\sqrt{\\sum_{i=1}^{n} (x_i-y_i)^2}$$\n",
    "\n",
    "\n",
    "4. **Chebyshev distance or $L_\\infty$ distance or uniform distance**: This distance is related to the uniform norm and measured by \n",
    "$$L_{\\infty}(\\mathbf{x, y})=\\max_{i=1} {|x_i-y_i|}$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7648d870",
   "metadata": {},
   "source": [
    "Here, is the code for in genral $L_p$ distance formula. In this project, we used $L_p$ distance and varies the value of $p$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "39d5cbd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lp_distance(x,w):\n",
    "    \"\"\"\n",
    "    This is the fucntion for measuring $L_p$ distance formula which takes two arguments and return the distance.\n",
    "    \n",
    "    The two arguments are:\n",
    "    \n",
    "    x:\n",
    "      a 2-dimensional Numpy array \n",
    "    \n",
    "    w:\n",
    "       a 1-dimensional Numpy array \n",
    "              \n",
    "    Returns:\n",
    "    \n",
    "    distance:\n",
    "            a 1-dimensional Numpy array whose i-th entry\n",
    "            is the L_p distance between i-th row of x and w\n",
    "    \n",
    "    \"\"\"\n",
    "    distance = np.power(np.sum((np.abs(x-w))**p, axis=1), (1/p))\n",
    "    \n",
    "    return distance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e59228d9",
   "metadata": {},
   "source": [
    "### 3.2. k-NN Classifier Model:\n",
    "\n",
    "This is the code for k-NN method by using the distance function and it will take as a argument the training dataset, labels of training dataset, a test point which label will be predicted and an integer $n$ which defines the number of nearest neighboring training data points and will give us the predicted label of the test datapoint with the number of the nearest neighbour points and the label of nearest neighbour points. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b2b6e33c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn_classifier(training_data,training_label, x, n):\n",
    "    \"\"\"\n",
    "    This is the fucntion for  k-nearest neighbors (k-NN) algorithm which takes four arguments and returns a tuple.\n",
    "    \n",
    "    The four arguments are:\n",
    "    \n",
    "    training_data:\n",
    "                a 2-dimensional Numpy array in which each row is one element of the training data. \n",
    "              \n",
    "    training_label: \n",
    "                a 1-dimensional Numpy array with labels of the training data: the k-th element of this array \n",
    "                is the label corresponding to the k-th row of training_data. \n",
    "                \n",
    "        x:  \n",
    "            a 1-dimensional Numpy array with a data point we want to classify. \n",
    "            \n",
    "        n: \n",
    "            an integer specifying the number of neighbors to use for the classification.\n",
    "        \n",
    "   Returns:\n",
    "   \n",
    "   label:  \n",
    "         the predicted label of the point x \n",
    "         \n",
    "   neighbour: \n",
    "          a list of rows numbers of training_data which are the n nearest neighbours of x.\n",
    "          \n",
    "   nearest_neighbour_label:\n",
    "          a list of rows numbers of label of training_data which are the n nearest neighbours of x\n",
    "        \n",
    "            \n",
    "    \"\"\"\n",
    "    \n",
    "    # Calcualte the distance between the test data and training data\n",
    "    distance = lp_distance(x,training_data) \n",
    "    # Order the index of distance\n",
    "    nearest_neighbour = distance.argsort()[:n] \n",
    "    # Select n neartest neighbour data from test data \n",
    "    nearest_neighbour_data = training_data[nearest_neighbour[0:n]] \n",
    "    # Label of n neartest neighbour data\n",
    "    nearest_neighbour_label = training_label[nearest_neighbour[0:n]] \n",
    "    # Label which occurs maximum time\n",
    "    label = np.bincount(nearest_neighbour_label).argmax() \n",
    "\n",
    "    return nearest_neighbour, label, nearest_neighbour_label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfbbb055",
   "metadata": {},
   "source": [
    "### 3.3. Model Implementation:\n",
    "Now, we implement the KNN classifier for the given dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2307f42",
   "metadata": {},
   "source": [
    "**1. Data splitting**: \n",
    "\n",
    "\n",
    "For model implementation we need to spllit the dataset into training and test dataset. Among 60,000 images randomly choose 20000 images as training data and 10000 images as testing data. And for implementing the model, we use $L_2$ distance that means $p=2$. At first, the images shuffled randomly then 1st 20000  data points seleceted as training dataset with the corresponding labels and then 10000 data points seleceted as test dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6c9312db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomly ordered index\n",
    "rng = np.random.default_rng(200) \n",
    "reorder = rng.permutation(len(images))\n",
    "# Shuffling images\n",
    "images = images[reorder] \n",
    "# Shuffling labels\n",
    "labels = labels[reorder] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "10ce1ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = 20000\n",
    "testing_data = 10000\n",
    "\n",
    "# Select training images\n",
    "training_images = images[:training_data] \n",
    "# Select training images labels \n",
    "training_labels = labels[:training_data] \n",
    "# Select test images \n",
    "test_images = images[training_data:training_data+testing_data] \n",
    "# Select test images label \n",
    "test_labels = labels[training_data:training_data+testing_data] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2bfc302e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((20000, 784), (20000,), (10000, 784), (10000,))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_images.shape, training_labels.shape, test_images.shape, test_labels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "956443aa",
   "metadata": {},
   "source": [
    "**2. Predict the label of test data:**\n",
    "\n",
    "\n",
    "Now apply the model to predict the label of test data. Initially for $n=5$, the model gives us the label of the test point with these five neighbours.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aef5e721",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_number=1999\n",
    "p=2\n",
    "nearest_neighbour, label, nearest_neighbour_label  = knn_classifier(training_images, \n",
    "                                                                     training_labels, \n",
    "                                                                     test_images[test_number], \n",
    "                                                                     n=5)\n",
    "    \n",
    "print(\"Predicted label for the test data is:\", label)\n",
    "print(\"The five nearest neighbors are:\", nearest_neighbour)\n",
    "print(\"The labels of five nearest neighbors are:\", nearest_neighbour_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e4b17c2",
   "metadata": {},
   "source": [
    "We see that the label of the test data and three nearest neighbour is same i.e 3. To check that the prediction iss correct, let find the actual label of the test image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de6d7338",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(test_images[test_number].reshape(28,28),cmap=\"Greys\")\n",
    "plt.title(test_labels[test_number])\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c00bf971",
   "metadata": {},
   "source": [
    "The predicted label is similar to actual label. So the prediction is correct. So far we could find the class of a single data point. \n",
    "This function is defined only for predicting the class of a single input data point. For the prediction of a whole data set later we use this function in another function. Now we define some function to get the class of a full data set and accuracy measurement."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "912e221d",
   "metadata": {},
   "source": [
    "**3. Accuracy of prediction:**\n",
    "\n",
    "Our k-NN model can predict the result for only a single data point. For calculating the accuracy percentage we need a number of test data points and their predicted class by the knn_classifier function.  Now we define a function which will take a set of test images without labels and will assign labels to them by using the knn_classifier function. This function also gives the nearest k-neighbors for each test point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2409bd70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getting_actual_labels(training_set, train_labels, test_set, n, method=knn_classifier):\n",
    "    \"\"\"\n",
    "    This is the function for k-nearest neighbors (KNN)  model for a set of test data which takes five arguments \n",
    "    and returns a tuple.\n",
    "    \n",
    "    The five arguments are:\n",
    "        training_set:\n",
    "                    a 2-dimensional Numpy array whose every row represents a training data set.\n",
    "        train_labels:\n",
    "                     a 1-dimensional Numpy array whose entries represent labels of the training data.\n",
    "        test_set: \n",
    "                a 2-dimensional Numpy array whose each row represents a test data point.\n",
    "        n : \n",
    "            an integer specifying the number of neighbors to use for the classification.\n",
    "        method:\n",
    "              we used knn_classifier method for this function.\n",
    "            \n",
    "   \n",
    "   Returns:\n",
    "        predicted_labels:\n",
    "                       a list of labels for the test dataset.\n",
    "        k_neighbors:\n",
    "                   a list of lists whose each list represets the row number of for the corresonding \n",
    "                    test data point.\n",
    "    \"\"\"\n",
    "    # Empty list for the predicted labels\n",
    "    predicted_labels = [] \n",
    "    # Empty list for k-nearest neighbors\n",
    "    k_neighbors = [] \n",
    "    \n",
    "    for x in range(len(test_set)):\n",
    "        result = method(training_set, train_labels, test_set[x], n) \n",
    "        predicted_labels.append(result[0])\n",
    "        k_neighbors.append(result[1])\n",
    "        \n",
    "    return predicted_labels, k_neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c452777b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def percentage_accuracy(actual_labels, predicted_labels):\n",
    "    \"\"\"\n",
    "    This is the funcition for finding the percentage fraction of test dataset predicted correctly \n",
    "    which has two argumanets and returns the accuracy.\n",
    "    \n",
    "    \n",
    "    The two arguments are:\n",
    "        actual_labels:\n",
    "                     a 1-dimensional Numpy array whose each entry is a actual label of the test dataset.\n",
    "        predicted_labels: \n",
    "                     a 1-dimensional Numpy array whose each entry is predicted label by knn_classifier.\n",
    "        \n",
    "    Returns:\n",
    "        accuracy: \n",
    "                a real number percentage of the predicted labels which are correctely predicted.\n",
    "    \"\"\"\n",
    "    \n",
    "    accuracy = sum(predicted_labels==actual_labels)/len(actual_labels)*100\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7aa2d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#predict the label of set of data points\n",
    "k_neighbors, predicted_labels = getting_actual_labels(training_set=training_images,\n",
    "                                                      train_labels=training_labels,\n",
    "                                                      test_set=test_images, n=5, \n",
    "                                                      method=knn_classifier) \n",
    "\n",
    "percentage_accuracy(actual_labels=test_labels, predicted_labels=predicted_labels) \n",
    "\n",
    "accuracy = percentage_accuracy(actual_labels=test_labels, predicted_labels=predicted_labels)\n",
    "print(\"The accuracy of the k-NN classifier model for three nearest neighbours and L2 distance is \", accuracy, \"percent.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fb853c4",
   "metadata": {},
   "source": [
    "**4. Confusion Matrix to visualize classification accuracy:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7032d35c",
   "metadata": {},
   "outputs": [],
   "source": [
    "c=np.zeros((10,10), dtype=int)\n",
    "for i in range(len(test_labels)):\n",
    "    c[predicted_labels[i], test_labels[i]]+=1\n",
    "print(f\"Confusion matrix: \\n {c}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "526cb1da",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 12))\n",
    "value_counts = [\"{0:0.0f}\".format(value) for value in\n",
    "                c.flatten()]\n",
    "percentages = [\"{0:.2%}\".format(per) for per in\n",
    "                     (c/np.sum(c, axis=1)).flatten()]\n",
    "cell_labels = [f\"{val}\\n{per}\" for val, per in\n",
    "          zip(value_counts, percentages)]\n",
    "cell_labels = np.asarray(cell_labels).reshape(10,10)\n",
    "sns.heatmap(c, \n",
    "            annot=True,\n",
    "            annot_kws = {\"fontsize\": 16},\n",
    "            cbar=True,\n",
    "            linewidth=2,\n",
    "            square=True,\n",
    "            cmap=\"Blues_r\"\n",
    "           )\n",
    "plt.xlabel(\"Predictions\")\n",
    "plt.ylabel(\"Actual labels\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc34d2b5",
   "metadata": {},
   "source": [
    "**5. Classification with perfect certainty:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7987f876",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_labels_array = np.array(predicted_labels).reshape(len(predicted_labels), -1)\n",
    "\n",
    "# k closest neighbors labels \n",
    "k_neighbors_labels = training_labels[k_neighbors]\n",
    "\n",
    "# Calculating the number of test point whose predicted labels match with all the k closest neighbors\n",
    "perfect_ceratinty_1 = np.sum(np.sum(k_neighbors_labels==predicted_labels_array, axis=1)==5) \n",
    "perfect_ceratinty = perfect_ceratinty_1/len(predicted_labels)\n",
    "\n",
    "print(\"The fraction of images classified correctly with perfect certainty\", perfect_ceratinty)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7abbef8",
   "metadata": {},
   "source": [
    "The above result shows that almost 90% images were classififed with perfect certainity. That is in these the mehod had not tie sitution to predict the class because all the neigbors were in favor of the test data. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3637a5d8",
   "metadata": {},
   "source": [
    "## 4. Comparison:\n",
    "\n",
    "In this section, we run our k-NN classifier model to get the percentage accuracy vs varying different parameters like different size of training data, different types of distance, varying the neighbour size. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7aa8b9a",
   "metadata": {},
   "source": [
    "### 4.1. Accuracy versue size of the training set:\n",
    "\n",
    "Here we check how the accuracy percentage of recognizing the digits in the test data set varies depending on the size of test data sets. For this, we create a list of training dataset of different size then for each data set we apply our k-NN model. We completed this work for $L_2$ distance and three neighbours."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30402377",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_size = list(range(10000, 60000, 5000))\n",
    "# Creating empty list for percentage accuracy of the training set\n",
    "percentage_accuracy_ts = []  \n",
    "\n",
    "for training_data in train_set_size:\n",
    "    testing_data = 10000\n",
    "    # Select training images\n",
    "    training_images = images[:training_data] \n",
    "    # Select training image labels\n",
    "    training_labels = labels[:training_data] \n",
    "    # Select test images \n",
    "    test_images = images[training_data: training_data+testing_data] \n",
    "    # Select test images label\n",
    "    test_labels = labels[training_data: training_data+testing_data] \n",
    "    \n",
    "    _,predicted_labels = getting_actual_labels(training_set=training_images,\n",
    "                                               train_labels=training_labels,\n",
    "                                               test_set=test_images, \n",
    "                                               n=5, \n",
    "                                               method=knn_classifier)\n",
    "    \n",
    "    percentage_accuracy_ts.append(percentage_accuracy(actual_labels=test_labels,\n",
    "                                                  predicted_labels=predicted_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d73e7ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_accuracy_ts = round(max(percentage_accuracy_ts),2)\n",
    "size_max_accuracy = train_set_size[percentage_accuracy_ts.index(max(percentage_accuracy_ts))]\n",
    "plt.style.use('seaborn')\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.plot(train_set_size, percentage_accuracy_ts, '-')\n",
    "plt.plot(size_max_accuracy, max_accuracy_ts,'o')\n",
    "plt.xlabel('Size of training sets', fontsize=12)\n",
    "plt.ylabel('Accuracy percentage', fontsize=12)\n",
    "plt.title(\"Accuracy  vs size of training sets.\", fontsize=20)\n",
    "plt.text(size_max_accuracy, max_accuracy_ts,(size_max_accuracy, max_accuracy_ts), fontsize=10)\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfa545c6",
   "metadata": {},
   "source": [
    "### 4.2. Accuracy versue the number of neighbors:\n",
    "\n",
    "\n",
    "Now  check the change of  accuracy percentage of recognizing the digits when we vary the size of nearest neighbours. So, first we create a list of number of nearest neighbours dataset and then for each data set we apply our k-NN model. We completed this work like as before for $L_2$ distance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57612315",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Varying the number of nearest neighbours \n",
    "number_of_neighbours = list(range(1,100)) \n",
    "percent_accuracy = []\n",
    "\n",
    "for n in number_of_neighbours:\n",
    "     _, predicted_labels = getting_actual_labels(training_set=training_images,\n",
    "                                                train_labels=training_labels,\n",
    "                                                test_set=test_images,\n",
    "                                                n=n, \n",
    "                                                method=knn_classifier)\n",
    "    \n",
    "     percent_accuracy.append(percentage_accuracy(actual_labels=test_labels, predicted_labels=predicted_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79f7c4d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_accuracy = max(percent_accuracy)\n",
    "p_val_max_accuracy = number_of_neighbours[percent_accuracy.index(max(percent_accuracy))]\n",
    "plt.style.use('seaborn')\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.plot(number_of_neighbours, percent_accuracy, '-')\n",
    "plt.plot(p_val_max_accuracy, max_accuracy,'o')\n",
    "plt.xlabel('Number of neighbors, $n$', fontsize=12)\n",
    "plt.ylabel('Accuracy percentage', fontsize=12)\n",
    "plt.title(\"Accuracy  vs the number of neighbours.\", fontsize=20)\n",
    "plt.text(p_val_max_accuracy, max_accuracy,(p_val_max_accuracy, max_accuracy), fontsize=10)\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fe471b2",
   "metadata": {},
   "source": [
    "From the figure it is noticable that we get the maximum accuracy for one nearest neighbours and it is 96.2 percent and then it decreases. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47443532",
   "metadata": {},
   "source": [
    "### 4.3. Accuracy versue Distance:\n",
    "\n",
    "\n",
    "So, it's the time to vary $L_p$ distance, for different value of $p$ and we vary $p$ from $0$ to $10$ and check how the percentage accuracy varies with $L_p$ distance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cda3531",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vary the value of p\n",
    "norm_list = list(range(1,10)) \n",
    "percent_accuracy_lp = []\n",
    "for p in norm_list:\n",
    "    _,predicted_labels = getting_actual_labels(training_set=training_images,\n",
    "                                               train_labels=training_labels,\n",
    "                                               test_set=test_images, \n",
    "                                               n=5, \n",
    "                                               method=knn_classifier)\n",
    "    \n",
    "    percent_accuracy_lp.append(percentage_accuracy(actual_labels=test_labels, predicted_labels=predicted_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c37029f",
   "metadata": {},
   "outputs": [],
   "source": [
    "percent_accuracy_lp = list(np.load(\"percent_accuracy_lp.npy\"))\n",
    "max_accuracy_lp = max(percent_accuracy_lp)\n",
    "p_val_max_accuracy_lp = norm_list[percent_accuracy_lp.index(max(percent_accuracy_lp))]\n",
    "plt.style.use('seaborn')\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.plot(norm_list, percent_accuracy_lp, '-')\n",
    "plt.plot(p_val_max_accuracy_lp, max_accuracy_lp,'o')\n",
    "plt.xlabel(' $p$ values in L_p norm', fontsize=12)\n",
    "plt.ylabel('Accuracy percentage', fontsize=12)\n",
    "plt.title(\"Accuracy  vs distance\", fontsize=20)\n",
    "plt.text(p_val_max_accuracy_lp,max_accuracy_lp,(p_val_max_accuracy_lp, max_accuracy_lp), fontsize=10)\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c25231b5",
   "metadata": {},
   "source": [
    "So from the figure, we see that, the accuracy is alsmost same for $L_1$ to $L_7$ norm, we get the maximum accuracy for $L_7$ norm which is 96.63% then the accuracy decreases.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84c7a6c2",
   "metadata": {},
   "source": [
    "## 5. Weighted k-NN Method:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ed41ed9",
   "metadata": {},
   "source": [
    "### 5.1. Weighted k-NN algorithm:\n",
    "\n",
    "**Weighted k-NN method Algorithm [3]:** \n",
    "\n",
    "* Start with training data point say $x$\n",
    "* Consider a new test data point say $y$\n",
    "* Compute distance between $x$ and $y$ namely $d(x,y)$ and then $k$ closest neighbors are selected.\n",
    "* The weight for $i$th nearest neighbour is defined as $$W_i=\\frac{1}{d(x_i, y)}$$ \n",
    "* The label for $y$ is assigned as $$y^*=arg\\, \\max_{C} \\sum_{(x_i,y_i)\\in D'} W_i \\delta(C=y_i')$$ where \n",
    "* $C$ set of classes,\n",
    "\n",
    "* $D'$ is the set of all nearest neigbours with labels,\n",
    "\n",
    "* $y_i'$ is the class label for the $i$th nearest neighbour,\n",
    "\n",
    "* $\\delta (.)$ is the Dirac-Delta function that takes the value 1 if its argumentis true and 0 otherwise. \n",
    "\n",
    "\n",
    "Here is the code for weighted k-NN method by using the distance function and it will take as a argument the training dataset, labels of training dataset, a test point which label will be predicted and an integer $n$ which defines the number of nearest neighboring training data points and will give us the predicted label of the test datapoint with the number of the nearest neighbour points and the label of nearest neighbour points. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5829170",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_knn(training_data, training_label, x, n):\n",
    "    \"\"\"\n",
    "    This is the fucntion for  the weighted k-nearest neighbors (KNN) algorithm \n",
    "    which takes four arguments and returns a tuple.\n",
    "    \n",
    "    The four arguments are:\n",
    "    training_data:\n",
    "                a 2-dimensional Numpy array in which each row is one element of the training data. \n",
    "              \n",
    "    training_label: \n",
    "                a 1-dimensional Numpy array with labels of the training data: the k-th element of this array \n",
    "                is the label corresponding to the k-th row of training_data. \n",
    "                \n",
    "        x:  \n",
    "            a 1-dimensional Numpy array with a data point we want to classify. \n",
    "            \n",
    "        n: \n",
    "            an integer specifying the number of neighbors to use for the classification.\n",
    "        \n",
    "   Returns:\n",
    "   \n",
    "   label:  \n",
    "         the predicted label of the point x \n",
    "         \n",
    "   nearest_neighbour: \n",
    "          a list of rows numbers of training_data which are the n nearest neighbours of x.\n",
    "          \n",
    "   nearest_neighbour_label:\n",
    "          a list of rows numbers of label of training_data which are the n nearest neighbours of x\n",
    "            \n",
    "    \"\"\"\n",
    "    \n",
    "    # Calcualte the distance between the test data and training data\n",
    "    distance = lp_distance(x, training_data) \n",
    "    # Order the index of distance\n",
    "    nearest_neighbour = distance.argsort()[:n] \n",
    "    # Select n neartest neighbour data from test data \n",
    "    nearest_neighbour_data = training_data[nearest_neighbour[0:n]] \n",
    "    # Label of n neartest neighbour data\n",
    "    nearest_neighbour_label = training_label[nearest_neighbour[0:n]] \n",
    "    # Calculate the weighted distance\n",
    "    w_distance = 1/(distance[nearest_neighbour[0:n]]) \n",
    "    # Calculate the class wise summation\n",
    "    class_sum = np.zeros(10) \n",
    "    # Sums up the weighted distances for each class label based on the nearest neighbor labels\n",
    "    np.add.at(class_sum, nearest_neighbour_label, w_distance)\n",
    "    # Label which occurs maximum summation time\n",
    "    label = np.argmax(class_sum) \n",
    "    # List n nearest neighbour\n",
    "    neighbors = list(nearest_neighbour_label[0:n]) \n",
    "    \n",
    "    return label, nearest_neighbour, nearest_neighbour_label \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "849eacb7",
   "metadata": {},
   "source": [
    "### 5.2. Implementation of Weighted k-NN method:\n",
    "\n",
    "\n",
    "Now we implement the weighted k-NN model for the given datset with the same procedure as we did for k-NN method. And take same size of training data and testing data and $L_2$ distance.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e73cc333",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data=20000\n",
    "testing_data=10000\n",
    "\n",
    "training_images = images[:training_data]\n",
    "training_labels = labels[:training_data]\n",
    "test_images = images[training_data: training_data+testing_data]\n",
    "test_labels = labels[training_data: training_data+testing_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "692009ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_number=1000\n",
    "p=2\n",
    "label, nearest_neighbour, nearest_neighbour_label = weighted_knn(training_images, \n",
    "                                                                 training_labels, \n",
    "                                                                 test_images[test_number], \n",
    "                                                                 n=5)\n",
    "print(\"The prediction label for the test data is\",  label) \n",
    "print(\"The three nearest neighbours with $L_2$ distance are\",nearest_neighbour)\n",
    "print(\"The label of the three nearest neighbours with $L_2$ distance are\",nearest_neighbour_label)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e31a44a9",
   "metadata": {},
   "source": [
    "We see that the label of the test data and three nearest neighbour is same i.e 3. To check that the prediction iss correct, let find the actual label of the test image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "300d1020",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(test_images[test_number].reshape(28,28),cmap=\"Greys\")\n",
    "plt.title(test_labels[test_number])\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "154187ce",
   "metadata": {},
   "source": [
    "The predicted label is similar to actual label. So the prediction is correct. So far we could find the class of a single data point. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da6aa71a",
   "metadata": {},
   "source": [
    "For more understanding, we need to find the percentage accuracy of the prediction on the test set. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58cdac30",
   "metadata": {},
   "source": [
    "### 5.3. Accuracy with weighted k-NN: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db24da67",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_labels_w, k_neighbors_w = getting_actual_labels(training_set=training_images,\n",
    "                                                          train_labels=training_labels,\n",
    "                                                          test_set=test_images, \n",
    "                                                          n=5, \n",
    "                                                          method=weighted_knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c45a18f",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = percentage_accuracy(actual_labels=test_labels, predicted_labels=predicted_labels_w)\n",
    "print(\"The accuracy of the weighted k-NN classifier model for three nearest neighbours and L2 distance is \", accuracy, \"percent.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cde652e1",
   "metadata": {},
   "source": [
    "So, the above percentage accuracy shows that the weighted  k−NN gives better accuracy than the  𝑘−NN on the same test set. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "038e76fd",
   "metadata": {},
   "source": [
    "### 5.4. Accuracy versue the number of neighbours with weighted k-NN "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9ba064d",
   "metadata": {},
   "source": [
    "Now  check the change of  accuracy percentage of recognizing the digits when we vary the size of nearest neighbours like as we did this before for k-NN model by using $L_2$ distance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e267bb43",
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_neighbours_w = list(range(1,100))\n",
    "percent_accuracy_w = []\n",
    "\n",
    "for n in number_of_neighbours_w:\n",
    "     predicted_labels,_ = getting_actual_labels(training_set=training_images,\n",
    "                                                train_labels=training_labels,\n",
    "                                                test_set=test_images, \n",
    "                                                n=n, \n",
    "                                                method=weighted_knn)\n",
    "    \n",
    "     percent_accuracy_w.append(percentage_accuracy(actual_labels=test_labels, predicted_labels=predicted_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c5a7a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_accuracy = max(percent_accuracy_w)\n",
    "p_val_max_accuracy = number_of_neighbours[percent_accuracy_w.index(max(percent_accuracy_w))]\n",
    "plt.style.use('seaborn')\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.plot(number_of_neighbours_w, percent_accuracy_w, '-')\n",
    "plt.plot(p_val_max_accuracy, max_accuracy,'o')\n",
    "plt.xlabel('Number of neighbors, $n$', fontsize=12)\n",
    "plt.ylabel('Accuracy percentage', fontsize=12)\n",
    "plt.title('Accuracy  vs the number of neighbours', fontsize=20)\n",
    "plt.text(p_val_max_accuracy,max_accuracy,(p_val_max_accuracy, max_accuracy), fontsize=10)\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b545d49",
   "metadata": {},
   "source": [
    "So, the weighted k-NN gives 96.34 percent accuracy which is better than the accuracy given by k-NN. So weighted k-NN gives better result. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "160bfbb6",
   "metadata": {},
   "source": [
    "## 6. Conclusion:\n",
    "\n",
    "\n",
    "In this project work, we used k-NN method for recognizing handwritting digits for MNIST dataset. For eavaluating the performance of our model that means how the model predicts the label of of digits, we checked the percentage accuarcy and see a very good accuarcy. Definitely there are  some error in the pridiction which is very natural and it occurs for different reasons. We measured the percentage of images classified correctly with perfect certainity. Also, we checked the percentage accuracy for differnt size of training dataset, nearest neighbour and measuring differnt $L_p$ distance. And we see that, we get the highest accuaracy when the training size is 55000, number of nearest neughbours, $n=1$ and for $L_7$ distance. We also implemented weighted k-NN model for the same dataset. The weighted k-NN gives the better accuracy than the k-NN model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20f955f0",
   "metadata": {},
   "source": [
    "## 7. References:\n",
    "\n",
    "\n",
    "1. https://en.wikipedia.org/wiki/MNIST_database\n",
    "2. Class lectures of MTH-548 course.\n",
    "3. Yigit, H. (2013, November). A weighting approach for KNN classifier. In 2013 international conference on electronics, computer and computation (ICECCO) (pp. 228-231). IEEE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca284fcd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abdb4656",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aa4df28",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
